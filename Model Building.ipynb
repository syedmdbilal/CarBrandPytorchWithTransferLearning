{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070577f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import webcolors\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('car.jpg')\n",
    "\n",
    "# Resize the image to a smaller size to speed up processing\n",
    "img = cv2.resize(img, (200, 200))\n",
    "\n",
    "# Convert the image to the HSV color space\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the color ranges for the colors you want to detect\n",
    "color_ranges = {\n",
    "    'red': [(0, 50, 50), (10, 255, 255)],\n",
    "    'orange': [(10, 50, 50), (20, 255, 255)],\n",
    "    'yellow': [(20, 50, 50), (30, 255, 255)],\n",
    "    'green': [(30, 50, 50), (60, 255, 255)],\n",
    "    'blue': [(100, 50, 50), (130, 255, 255)],\n",
    "    'purple': [(130, 50, 50), (170, 255, 255)],\n",
    "}\n",
    "\n",
    "# Find the dominant color in the image\n",
    "dominant_color = None\n",
    "max_pixels = 0\n",
    "for color_name, (lower, upper) in color_ranges.items():\n",
    "    mask = cv2.inRange(hsv_img, np.array(lower), np.array(upper))\n",
    "    pixels = cv2.countNonZero(mask)\n",
    "    if pixels > max_pixels:\n",
    "        dominant_color = color_name\n",
    "        max_pixels = pixels\n",
    "\n",
    "# Print the color name\n",
    "if dominant_color is not None:\n",
    "    print('The dominant color in the image is', dominant_color)\n",
    "    # Get the corresponding color name from the webcolors library\n",
    "    rgb_color = webcolors.name_to_rgb(dominant_color)\n",
    "    print('RGB color:', rgb_color)\n",
    "else:\n",
    "    print('No dominant color found in the image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39af8d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define color ranges for each color\n",
    "color_ranges = {\n",
    "    'red': ([0, 50, 50], [10, 255, 255]),\n",
    "    'orange': ([11, 50, 50], [20, 255, 255]),\n",
    "    'yellow': ([21, 50, 50], [30, 255, 255]),\n",
    "    'green': ([31, 50, 50], [80, 255, 255]),\n",
    "    'blue': ([101, 50, 50], [130, 255, 255]),\n",
    "    'purple': ([131, 50, 50], [170, 255, 255]),\n",
    "    'pink': ([171, 50, 50], [180, 255, 255]),\n",
    "    'brown': ([0, 50, 50], [20, 255, 100])\n",
    "}\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread('Audi.jpg')\n",
    "\n",
    "# Resize image for faster processing\n",
    "img = cv2.resize(img, (600, 400))\n",
    "\n",
    "# Convert image to HSV color space\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Iterate through each color range to find dominant color\n",
    "color_pixels = []\n",
    "for color, (lower, upper) in color_ranges.items():\n",
    "    mask = cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "    pixels = cv2.countNonZero(mask)\n",
    "    color_pixels.append((color, pixels))\n",
    "\n",
    "# Get color with the highest pixel count\n",
    "dominant_color = max(color_pixels, key=lambda x: x[1])[0]\n",
    "\n",
    "# Print the dominant color name\n",
    "print('The car color is:', dominant_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84197482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define color range for each color\n",
    "color_ranges = {\n",
    "    'red': ((0, 50, 50), (10, 255, 255), (170, 50, 50), (180, 255, 255)),\n",
    "    'orange': ((11, 50, 50), (25, 255, 255)),\n",
    "    'yellow': ((26, 50, 50), (35, 255, 255)),\n",
    "    'green': ((36, 50, 50), (70, 255, 255)),\n",
    "    'blue': ((100, 50, 50), (130, 255, 255)),\n",
    "    'purple': ((131, 50, 50), (160, 255, 255)),\n",
    "    'pink': ((161, 50, 50), (169, 255, 255))\n",
    "}\n",
    "\n",
    "# Define function to detect color of car\n",
    "def detect_car_color(image):\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    for color_name, color_range in color_ranges.items():\n",
    "        for lower_range, upper_range in zip(color_range[::2], color_range[1::2]):\n",
    "            lower = np.array(lower_range)\n",
    "            upper = np.array(upper_range)\n",
    "            mask = cv2.inRange(hsv_image, lower, upper)\n",
    "            if cv2.countNonZero(mask) > 0:\n",
    "                return color_name\n",
    "    return 'unknown'\n",
    "\n",
    "# Load image of car\n",
    "image = cv2.imread('Audi.jpg')\n",
    "\n",
    "# Detect car color and print color name\n",
    "color_name = detect_car_color(image)\n",
    "print('Car color: ', color_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5c90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define color ranges for each color\n",
    "colors = {\"white\": ([180, 180, 180], [255, 255, 255]),\n",
    "          \"black\": ([0, 0, 0], [80, 80, 80]),\n",
    "          \"red\": ([17, 15, 100], [50, 56, 200]),\n",
    "          \"blue\": ([86, 31, 4], [220, 88, 50]),\n",
    "          \"yellow\": ([25, 146, 190], [62, 174, 250])}\n",
    "\n",
    "# Load the car image\n",
    "img = cv2.imread('car_image.jpg')\n",
    "\n",
    "# Resize image to reduce processing time\n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Convert image to HSV color space\n",
    "hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Loop through each color range and count pixels that fall within that range\n",
    "color_counts = {}\n",
    "for color, (lower, upper) in colors.items():\n",
    "    lower = np.array(lower, dtype=\"uint8\")\n",
    "    upper = np.array(upper, dtype=\"uint8\")\n",
    "    mask = cv2.inRange(hsv_img, lower, upper)\n",
    "    count = cv2.countNonZero(mask)\n",
    "    color_counts[color] = count\n",
    "\n",
    "# Determine the dominant color by finding the color with the highest count\n",
    "dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "# Print the dominant color name\n",
    "print(\"The car color is:\", dominant_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Define color ranges for each color\n",
    "colors = {\"white\": ([180, 180, 180], [255, 255, 255]),\n",
    "          \"black\": ([0, 0, 0], [80, 80, 80]),\n",
    "          \"red\": ([17, 15, 100], [50, 56, 200]),\n",
    "          \"blue\": ([86, 31, 4], [220, 88, 50]),\n",
    "          \"yellow\": ([25, 146, 190], [62, 174, 250])}\n",
    "\n",
    "# Load the car image\n",
    "img = cv2.imread('yellow.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: could not read image file\")\n",
    "else:\n",
    "    # Resize image to reduce processing time\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Convert image to HSV color space\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Loop through each color range and count pixels that fall within that range\n",
    "    color_counts = {}\n",
    "    for color, (lower, upper) in colors.items():\n",
    "        lower = np.array(lower, dtype=\"uint8\")\n",
    "        upper = np.array(upper, dtype=\"uint8\")\n",
    "        mask = cv2.inRange(hsv_img, lower, upper)\n",
    "        count = cv2.countNonZero(mask)\n",
    "        color_counts[color] = count\n",
    "\n",
    "    # Determine the dominant color by finding the color with the highest count\n",
    "    dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "    # Print the dominant color name\n",
    "    print(\"The car color is:\", dominant_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Load color values from csv file\n",
    "colors = {}\n",
    "with open('colors.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        name, rgb = row\n",
    "        colors[name] = [int(x) for x in rgb.split(',')]\n",
    "\n",
    "# Load the car image\n",
    "img = cv2.imread('bl.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: could not read image file\")\n",
    "else:\n",
    "    # Resize image to reduce processing time\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Convert image to HSV color space\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Loop through each color in the csv file and count pixels that fall within that range\n",
    "    color_counts = {}\n",
    "    for color, rgb in colors.items():\n",
    "        lower = np.array(rgb, dtype=\"uint8\")\n",
    "        upper = np.array(rgb, dtype=\"uint8\") + 20\n",
    "        mask = cv2.inRange(img, lower, upper)\n",
    "        count = cv2.countNonZero(mask)\n",
    "        color_counts[color] = count\n",
    "\n",
    "    # Determine the dominant color by finding the color with the highest count\n",
    "    dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "    # Print the dominant color name\n",
    "    print(\"The car color is:\", dominant_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "# Load color values from csv file\n",
    "colors = {}\n",
    "with open('colors.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        name = row[0]\n",
    "        rgb = [int(x) for x in row[3:6]]\n",
    "        colors[name] = rgb\n",
    "\n",
    "# Load the car image\n",
    "img = cv2.imread('yel.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: could not read image file\")\n",
    "else:\n",
    "    # Resize image to reduce processing time\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Convert image to HSV color space\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Loop through each color in the csv file and count pixels that fall within that range\n",
    "    color_counts = {}\n",
    "    for color, rgb in colors.items():\n",
    "        lower = np.array(rgb, dtype=\"uint8\")\n",
    "        upper = np.array(rgb, dtype=\"uint8\") + 20\n",
    "        mask = cv2.inRange(img, lower, upper)\n",
    "        count = cv2.countNonZero(mask)\n",
    "        color_counts[color] = count\n",
    "\n",
    "    # Determine the dominant color by finding the color with the highest count\n",
    "    dominant_color = max(color_counts, key=color_counts.get)\n",
    "\n",
    "    # Print the dominant color name\n",
    "    print(\"The car color is:\", dominant_color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fd05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7e8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "# Download the pre-trained YOLOv3 model for object detection\n",
    "execution_path = os.getcwd()\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path , \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "# Load the image of the car you want to analyze\n",
    "input_image = \"car.jpg\"\n",
    "\n",
    "# Use the object detection model to detect cars in the image\n",
    "detections = detector.detectObjectsFromImage(input_image=input_image, output_image_path=os.path.join(execution_path , \"image_new.jpg\"))\n",
    "# Loop over the detected cars and print their make and model\n",
    "for eachObject in detections:\n",
    "    if eachObject[\"name\"] == \"car\":\n",
    "        print(\"Car Make: \", eachObject[\"make\"])\n",
    "        print(\"Car Model: \", eachObject[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6366a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load the image of the car you want to analyze\n",
    "img = cv2.imread('car.jpg')\n",
    "\n",
    "# Resize image to reduce processing time\n",
    "scale_percent = 50 # percent of original size\n",
    "width = int(img.shape[1] * scale_percent / 100)\n",
    "height = int(img.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Convert the image from BGR to RGB\n",
    "rgb_img = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Flatten the image\n",
    "pixels = rgb_img.reshape((rgb_img.shape[0] * rgb_img.shape[1], 3))\n",
    "\n",
    "# Use KMeans clustering to extract the dominant color\n",
    "n_colors = 1 # Number of dominant colors to extract\n",
    "kmeans = KMeans(n_clusters=n_colors)\n",
    "kmeans.fit(pixels)\n",
    "dominant_color = kmeans.cluster_centers_[0].astype(int)\n",
    "\n",
    "# Print the dominant color in RGB and hex format\n",
    "print(f\"Dominant color (RGB): {dominant_color}\")\n",
    "hex_color = '#{:02x}{:02x}{:02x}'.format(*dominant_color)\n",
    "print(f\"Dominant color (hex): {hex_color}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c02c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "# Load YOLO model\n",
    "execution_path = os.getcwd()\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(os.path.join(execution_path, \"yolo.h5\"))\n",
    "detector.loadModel()\n",
    "\n",
    "# Load car model and year data\n",
    "car_data = pd.read_csv(\"car_data.csv\")\n",
    "car_data.set_index(\"Model\", inplace=True)\n",
    "zxcd2e\n",
    "# Load test image\n",
    "img_path = \"Audi.jpg\"\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Detect cars in the image\n",
    "detections = detector.detectObjectsFromImage(input_image=img, output_image_path=os.path.join(execution_path , \"output.jpg\"), minimum_percentage_probability=30)\n",
    "\n",
    "# Process the car detections\n",
    "for detection in detections:\n",
    "    if detection[\"name\"] == \"car\":\n",
    "        x1, y1, x2, y2 = detection[\"box_points\"]\n",
    "        car_img = img[y1:y2, x1:x2]\n",
    "        car_img = cv2.cvtColor(car_img, cv2.COLOR_BGR2RGB)\n",
    "        car_img = cv2.resize(car_img, (224, 224))\n",
    "\n",
    "        # Predict the car model and year\n",
    "        predictions = model.predict(np.array([car_img]))\n",
    "        model_name = car_data.loc[np.argmax(predictions)][0]\n",
    "        year = car_data.loc[np.argmax(predictions)][1]\n",
    "        \n",
    "        # Print the results\n",
    "        print(\"Car Model:\", model_name)\n",
    "        print(\"Year:\", year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cython pillow>=7.0.0 numpy>=1.18.1 opencv-python>=4.1.2 torch>=1.9.0 --extra-index-url https://download.pytorch.org/whl/cpu torchvision>=0.10.0 --extra-index-url https://download.pytorch.org/whl/cpu pytest==7.1.3 tqdm==4.64.1 scipy>=1.7.3 matplotlib>=3.4.3 mock==4.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666dde64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Prediction import ImagePrediction\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "prediction = ImagePrediction()\n",
    "prediction.setModelTypeAsResNet()\n",
    "\n",
    "model_path = os.path.join(execution_path, \"resnet50_weights_tf_dim_ordering_tf_kernels.h5\")\n",
    "prediction.setModelPath(model_path)\n",
    "prediction.loadModel()\n",
    "\n",
    "# Load the image of the car you want to analyze\n",
    "car_image_path = os.path.join(execution_path, \"car.jpg\")\n",
    "\n",
    "predictions, probabilities = prediction.predictImage(car_image_path, result_count=1)\n",
    "\n",
    "# The predictions variable is a list of tuples, each containing the name of the make and the probability of the prediction\n",
    "make = predictions[0]\n",
    "probability = probabilities[0]\n",
    "\n",
    "print(\"The make of the car is: \" + make)\n",
    "print(\"The probability is: \" + str(probability))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d297aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import re\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "# Initialize the YOLOv3 model\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"yolo.h5\")\n",
    "detector.loadModel()\n",
    "\n",
    "# Initialize the pytesseract OCR engine\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Define the regex pattern to extract car model name and year\n",
    "pattern = r'([A-Za-z]+)\\s*(\\d{4})'\n",
    "\n",
    "# Load the car image\n",
    "image = cv2.imread(\"car_image.jpg\")\n",
    "\n",
    "# Detect objects using YOLOv3 model\n",
    "detections = detector.detectObjectsFromImage(input_image=image, output_image_path=\"car_detected.jpg\")\n",
    "\n",
    "# Loop through the detections to find car objects and extract their number plates\n",
    "for eachObject in detections:\n",
    "    if eachObject[\"name\"] == \"car\":\n",
    "        x1, y1, x2, y2 = eachObject[\"box_points\"]\n",
    "        car_image = image[y1:y2, x1:x2]\n",
    "        gray_car_image = cv2.cvtColor(car_image, cv2.COLOR_BGR2GRAY)\n",
    "        blur_car_image = cv2.GaussianBlur(gray_car_image, (5, 5), 0)\n",
    "        canny_car_image = cv2.Canny(blur_car_image, 50, 150)\n",
    "        contours, hierarchy = cv2.findContours(canny_car_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if w*h > 2000 and w/h > 1.5 and w/h < 3:\n",
    "                number_plate = gray_car_image[y:y+h, x:x+w]\n",
    "                text = pytesseract.image_to_string(number_plate, config='--psm 11')\n",
    "                match = re.search(pattern, text)\n",
    "                if match:\n",
    "                    car_model = match.group(1)\n",
    "                    car_year = match.group(2)\n",
    "                    print(\"Car Model: \", car_model)\n",
    "                    print(\"Car Year: \", car_year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b061a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "# Set the path to the dataset containing images of Audi cars and their corresponding labels\n",
    "dataset_path = r\"C:\\Users\\spavi\\OneDrive\\Desktop\\brand detector\\Audi\"\n",
    "\n",
    "# Set up the YOLOv3 model trainer\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "\n",
    "# Set the path to the pre-trained YOLOv3 weights file\n",
    "trainer.setModelPath(\"yolov4-tiny.weights\")\n",
    "\n",
    "# Set the number of classes in the dataset\n",
    "trainer.setNumberOfClasses(1)\n",
    "\n",
    "# Set the path to the directory to save the trained model\n",
    "output_dir = \"Audi\"\n",
    "trainer.setOutputPath(output_dir)\n",
    "\n",
    "# Set the path to the directory containing the validation set\n",
    "validation_dir = \"Audi\"\n",
    "trainer.setValidationPath(validation_dir)\n",
    "\n",
    "# Set the batch size for training\n",
    "trainer.setBatchSize(4)\n",
    "\n",
    "# Set the number of epochs to train for\n",
    "trainer.setEpochs(50)\n",
    "\n",
    "# Train the model\n",
    "trainer.trainModel(dataset_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cecf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba4b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some hyperparameters\n",
    "img_size = 224\n",
    "batch_size = 32\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generators for training and validation data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\spavi\\OneDrive\\Desktop\\brand detector\\dataset\\train',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc70c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_generator = val_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\spavi\\OneDrive\\Desktop\\brand detector\\dataset\\test',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False,\n",
    "                   input_shape=(img_size, img_size, 3))\n",
    "\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0466bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "# Add some fully connected layers on top for classification\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7dd64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt =SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853aba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_steps = train_generator.samples // train_generator.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecef04b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_steps = val_generator.n // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d79e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "    \n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc20274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new input images\n",
    "from PIL import Image\n",
    "test_image = Image.open(r'Audi.jpg')\n",
    "test_image = test_image.resize((img_size, img_size))\n",
    "test_image = np.array(test_image) / 255.0\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2202e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image)\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(predicted_class)\n",
    "#predicted_model_name = class_names\n",
    "#print(predicted_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63306f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import SGD\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3c6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "\n",
    "\n",
    "DIRECTORY = r\"C:\\Users\\spavi\\OneDrive\\Desktop\\brand detector\\dataset\\train\"\n",
    "CATEGORIES = [\"audi\",\"lamborgini\"]\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        data.append(image)\n",
    "        labels.append(category)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e0519",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "      test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8f3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are\n",
    "# left off\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "       input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "# construct the head of the model that will be placed on top of the\n",
    "# the base model\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
    "\n",
    "# place the head FC model on top of the base model (this will become\n",
    "# the actual model we will train)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ff93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all layers in the base model and freeze them so they will\n",
    "# *not* be updated during the first training process\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt =SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de96956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)\n",
    "    \n",
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28668e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "     target_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"car_brand_ford.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"car_brand.model\")\n",
    "\n",
    "# Load the new image\n",
    "image = cv2.imread(\"audi2.jpg\")\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "# Normalize the pixel values\n",
    "normalized_image = resized_image / 255.0\n",
    "\n",
    "# Add a batch dimension\n",
    "batched_image = tf.expand_dims(normalized_image, axis=0)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = model.predict(batched_image)\n",
    "\n",
    "# Get the predicted class label\n",
    "label = \"Audi\" if predictions[0][0] > predictions[0][1] else \"Lamborghini\"\n",
    "\n",
    "# Get the color for the label\n",
    "color = (0, 255, 0) if label == \"Audi\" else (0, 0, 255)\n",
    "\n",
    "# Draw the label and bounding box on the image\n",
    "cv2.putText(image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539ff84c",
   "metadata": {},
   "source": [
    "# Three label detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef62990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"car_model.h5\")\n",
    "\n",
    "# Load the new image\n",
    "image = cv2.imread(\"new_car.jpg\")\n",
    "\n",
    "# Resize the image\n",
    "resized_image = cv2.resize(image, (224, 224))\n",
    "\n",
    "# Normalize the pixel values\n",
    "normalized_image = resized_image / 255.0\n",
    "\n",
    "# Add a batch dimension\n",
    "batched_image = tf.expand_dims(normalized_image, axis=0)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = model.predict(batched_image)\n",
    "\n",
    "# Get the predicted class label\n",
    "if predictions[0][0] > predictions[0][1]:\n",
    "    label = \"Audi\"\n",
    "elif predictions[0][1] > predictions[0][2]:\n",
    "    label = \"Lamborghini\"\n",
    "else:\n",
    "    label = \"Ford\"\n",
    "\n",
    "# Get the color for the label\n",
    "color = (0, 255, 0) if label == \"Audi\" else ((0, 0, 255) if label == \"Lamborghini\" else (255, 255, 255))\n",
    "\n",
    "# Draw the label and bounding box on the image\n",
    "cv2.putText(image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, color, 2)\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530849fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to identify\n",
    "#color in images\n",
    "\n",
    "# Importing the libraries OpenCV and numpy\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the images\n",
    "img = cv2.imread(\"lam1.jpg\")\n",
    "\n",
    "# Resizing the image\n",
    "image = cv2.resize(img, (700, 600))\n",
    "\n",
    "# Convert Image to Image HSV\n",
    "hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Defining lower and upper bound HSV values\n",
    "lower = np.array([50, 100, 100])\n",
    "upper = np.array([70, 255, 255])\n",
    "\n",
    "# Defining mask for detecting color\n",
    "mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "# Display Image and Mask\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "# Make python sleep for unlimited time\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(\"lam1.jpg\")\n",
    "\n",
    "# Convert the image to RGB color space\n",
    "image = image.convert(\"RGB\")\n",
    "\n",
    "# Select a pixel\n",
    "x = 10\n",
    "y = 20\n",
    "pixel = image.getpixel((x, y))\n",
    "\n",
    "# Get the color\n",
    "red, green, blue = pixel\n",
    "\n",
    "# Print the color\n",
    "print(\"The color is: \" + str(red) + \", \" + str(green) + \", \" + str(blue))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114753c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
